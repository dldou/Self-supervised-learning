{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Self-supervised Learning\n",
    "\n",
    "Self-supervised learning is a 2 phases learning technique:  \n",
    "- first phase is destined to train the model on a task where we can implement an automatic way to labeled the dataset  \n",
    "  \n",
    "- second phase is intended to accomplish the real task. Thanks to the first phase, we start with pre-trained weights that might be closer to the values we'll obtained while during training. Moreover theoritically, we might need less labeled data to train our model  \n",
    "\n",
    "To simplify, we can see the technique as a form of fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfSupervisedMNIST(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SelfSupervisedMNIST, self).__init__()\n",
    "        self.encoder = nn.Sequential( nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, padding=1),\n",
    "                                      nn.MaxPool2d(2),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=0),\n",
    "                                      nn.MaxPool2d(2, padding=1),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=0),\n",
    "                                      nn.ReLU()\n",
    "                                    )\n",
    "        self.classification = nn.Sequential( nn.Linear(in_features=256, out_features=64),\n",
    "                                             nn.ReLU(),\n",
    "                                             nn.Linear(64, 4),\n",
    "                                             nn.Softmax(dim=1)\n",
    "                                           )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.classification(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, train_dataloader, test_dataloader, optimizer, loss_fn):#, metric):\n",
    "\n",
    "        self.model            = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader  = test_dataloader\n",
    "        self.optimizer        = optimizer\n",
    "        self.loss_fn          = loss_fn\n",
    "        #self.metric           = metric\n",
    "\n",
    "    def train_step(self, device):\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        self.model.train()\n",
    "\n",
    "        for i, (images, targets) in enumerate(self.train_dataloader, 0):\n",
    "        \n",
    "            #Data send to device + requires_grad=True\n",
    "            images, targets = images.requires_grad_().to(device), targets.to(device)\n",
    "            #Zero the gradient \n",
    "            self.optimizer.zero_grad()\n",
    "            #Predictions \n",
    "            outputs = self.model(images)\n",
    "            #Loss\n",
    "            epoch_loss = self.loss_fn(outputs, targets)\n",
    "            #Upgrade the gradients (backpropagate) and the optimizer\n",
    "            epoch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            #self.check_layers_values()\n",
    "\n",
    "        return epoch_loss\n",
    "\n",
    "    def test_step(self, device):\n",
    "\n",
    "        list_loss       = []\n",
    "        nof_predictions = 0.0\n",
    "        epoch_accuracy  = 0.0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (images, targets) in enumerate(self.test_dataloader, 0):\n",
    "\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                outputs = self.model(images)#.squeeze(1)\n",
    "                epoch_loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "                _, predictions = torch.max(outputs.data, 1)\n",
    "                nof_predictions += targets.size(0)\n",
    "\n",
    "                epoch_accuracy += (predictions == targets).sum().item()\n",
    "                \n",
    "            #Compute the accuracy over the test set\n",
    "            epoch_accuracy = (100*epoch_accuracy/nof_predictions)\n",
    "\n",
    "        return epoch_accuracy\n",
    "\n",
    "    def train_model(self, \n",
    "                    nof_epochs, batch_size, learning_rate, \n",
    "                    file_path_save_model, save_epoch_path,\n",
    "                    train_loss_name, accuracy_name, test_loss_name,\n",
    "                    best_accuracy_is_maximal = False,\n",
    "                    device='cuda:0'):\n",
    "\n",
    "        print(\"Starting training...\\n\")\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"The model will be running on\", device, \"device.\\n\")\n",
    "        \n",
    "        self.model.to(device)\n",
    "        best_accuracy = 0.0\n",
    "\n",
    "        for epoch in range(1, nof_epochs+1):\n",
    "\n",
    "            epoch_accuracy   = 0.0\n",
    "            train_epoch_loss = 0.0\n",
    "            test_epoch_loss  = 0.0\n",
    "\n",
    "            #Training\n",
    "            train_epoch_loss = self.train_step(device)\n",
    "            #Validation\n",
    "            epoch_accuracy   = self.test_step(device)\n",
    "        \n",
    "            print(f'Epoch: {epoch}, {train_loss_name}: {train_epoch_loss}, {accuracy_name}: {epoch_accuracy}%')\n",
    "            \n",
    "            #Save model when best accuracy is beaten\n",
    "            if best_accuracy_is_maximal:\n",
    "                if epoch_accuracy > best_accuracy:\n",
    "                    save_epoch_path = str(epoch) + \"best_accuracy.pth\"\n",
    "                    self.save_model(self.model, save_epoch_path)\n",
    "                    best_accuracy = epoch_accuracy\n",
    "            else:\n",
    "                if epoch_accuracy < best_accuracy:\n",
    "                    save_epoch_path = str(epoch) + \"best_accuracy.pth\"\n",
    "                    self.save_model(save_epoch_path)\n",
    "                    best_accuracy = epoch_accuracy                \n",
    "\n",
    "        # Saving the model\n",
    "        print('Saving the model...\\n')\n",
    "        self.model = self.model.to('cpu')\n",
    "        self.save_model(file_path_save_model)\n",
    "\n",
    "        print(\"Training finish.\\n\") \n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def save_model(self, file_path_save_model):\n",
    "        torch.save(self.model.state_dict(), file_path_save_model)\n",
    "\n",
    "    def load_model(self, file_path_to_model, device):\n",
    "        state_params = torch.load(file_path_to_model)\n",
    "        self.model.load_state_dict(state_params)\n",
    "\n",
    "    def check_layers_values(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            print(name, param.grad)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderBuilderFromList:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "\n",
    "        if not all(list_ for list_ in [X_train, y_train, X_test, y_test]):\n",
    "            raise ValueError(\"X or y mustn't be empty\")\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.X_test  = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "\n",
    "    def create_dataloaders(self, transform=None, batch_size=32, shuffle=True, type=torch.float32):\n",
    "\n",
    "        # Convert to tensor\n",
    "        X_train = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(self.y_train, dtype=torch.float32)\n",
    "\n",
    "        X_test = torch.tensor(self.X_test, dtype=torch.float32)\n",
    "        y_test = torch.tensor(self.y_test, dtype=torch.float32)\n",
    "\n",
    "        # Apply transforms if present\n",
    "        if transform is not None:\n",
    "            X_train = self.transform(X_train)\n",
    "            X_test  = self.transform(X_test)\n",
    "\n",
    "        # Create dataloader\n",
    "        train_dataset = TensorDataset(transform(self.X_train), self.y_train)\n",
    "        test_dataset  = TensorDataset(transform(self.X_test), self.y_test)\n",
    "        \n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        test_dataloader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        return train_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "class DataLoaderBuilderFromMNIST:\n",
    "\n",
    "    def __init__(self, dataloader):\n",
    "        self.X  = dataloader.data\n",
    "        self._y = dataloader.targets\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._X\n",
    "\n",
    "    @X.setter\n",
    "    def X(self, new_X_tensor):\n",
    "        self._X = new_X_tensor\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "\n",
    "    @y.setter\n",
    "    def y(self, angles):\n",
    "        self._y = angles\n",
    "\n",
    "    def random_angle(self, angles_list):\n",
    "        \"\"\"\n",
    "            Generate a random degrees from angles list and return a tensor of size _size that contains all of them\n",
    "        \"\"\"\n",
    "        random_idx_angles = torch.randint(low=0, high=4, size=(self.X.data.shape[0],), dtype=torch.long)\n",
    "        \n",
    "        return random_idx_angles\n",
    "\n",
    "    def rotator_images(self, angles):\n",
    "\n",
    "        batch_size = self.X.shape[0]\n",
    "        rotated_images = torch.zeros_like(self.X.unsqueeze(dim=1))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            image = self.X[i]\n",
    "            angle = angles[i].item()\n",
    "\n",
    "            if image.ndimension() == 2:\n",
    "                image = image.unsqueeze(0)\n",
    "\n",
    "            rotated_images[i] = transforms.functional.rotate(image, angle)\n",
    "\n",
    "        return rotated_images\n",
    "\n",
    "    def create_dataloaders(self, transform=None, batch_size=32, shuffle=True, _type=torch.float32):\n",
    "\n",
    "        self._X = torch.tensor(self._X, dtype=torch.float32)\n",
    "        self._y = torch.tensor(self._y, dtype=torch.long)\n",
    "\n",
    "        # Apply transforms if present\n",
    "        if transform is not None:\n",
    "            self._X = self.transform(self._X)\n",
    "\n",
    "        # Create dataloader\n",
    "        dataset = TensorDataset(self._X, self._y)\n",
    "        \n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        return dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayConvFilers(model, \n",
    "                      layer_name,\n",
    "                      optimizer, epoch,\n",
    "                      figsize=(2,2),\n",
    "                      suptitle=None, savefig=True\n",
    "                      ):\n",
    "\n",
    "    layer = model.state_dict()[layer_name]\n",
    "    n_filters, n_channels, height, width = layer.shape\n",
    "    total_filters = n_filters * n_channels\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    # Loop through each filter in the layer\n",
    "    for batch_idx in range(n_filters):\n",
    "\n",
    "        for channel_idx in range(n_channels):\n",
    "\n",
    "            filter = layer[batch_idx][channel_idx].cpu()\n",
    "            subplot_index = batch_idx * n_channels + channel_idx + 1\n",
    "            \n",
    "            ax = plt.subplot(n_filters, n_channels, subplot_index)\n",
    "            plt.imshow(filter, cmap='gray')\n",
    "            \n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "            \n",
    "            # Label the y-axis with the batch number\n",
    "            if (channel_idx==0):\n",
    "                ax.set_ylabel(\"Batch #{}\".format(batch_idx+1), fontsize=20)\n",
    "                \n",
    "            # Label the x-axis with the channel number\n",
    "            if batch_idx == (n_filters - 1):\n",
    "                ax.set_xlabel(\"Channel #{}\".format(channel_idx+1), fontsize=20)\n",
    "    \n",
    "    #Layout of the figure\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.92])\n",
    "\n",
    "    if suptitle == None:\n",
    "        filename = f\"{model.__class__.__name__}_{layer_name}_filters_{n_filters}_channels_{n_channels}_height_{height}_width_{width}.pdf\"\n",
    "        fig.suptitle(f\"Visualization of layer's filters on {model.__class__.__name__} model (unpruned)\\n\"\n",
    "                     f\"(Model characteristics - optimizer: {optimizer.__class__.__name__}, learning rate: {optimizer.state_dict()['param_groups'][0]['lr']}, number of epochs: {epoch})\\n\\n\"\n",
    "                     f\"Layer name: {layer_name}, Filters' size: ({height}x{width})\",\n",
    "                     fontsize=25)\n",
    "        \n",
    "    else:\n",
    "        filename = f\"{suptitle}.pdf\"\n",
    "        fig.suptitle(suptitle, fontsize=25)\n",
    "\n",
    "    #Save figure\n",
    "    if savefig and suptitle == None:\n",
    "        plt.savefig(str(model.__class__.__name__) + \"_\" + layer_name + \"_\" \n",
    "                    + \"batch_\" + str(n_filters) + \"_\" \n",
    "                    + \"channels_\" + str(n_channels)  + \"_\" \n",
    "                    + \"height\" + str(height) + \"_\" \n",
    "                    + \"width_\" + str(width)  \n",
    "                    + \".pdf\"\n",
    "                    )\n",
    "    else:\n",
    "        plt.savefig(suptitle + \".pdf\")\n",
    "    \n",
    "    #Show figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    #If model need to been trained turn train to True and load to False\n",
    "    train = True\n",
    "    #If model need to be loaded from a pth file, turn train to False and load to True\n",
    "    load = False\n",
    "\n",
    "    # Model\n",
    "    sslModel = SelfSupervisedMNIST()\n",
    "    #summary(sslModel, (1,28,28))\n",
    "\n",
    "    #Data\n",
    "    transform = transforms.Compose([transforms.CenterCrop(28),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=0, std=0.2)\n",
    "                                    ])\n",
    "                                    \n",
    "    # Don't forget to take a pourcentage of data\n",
    "    mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)  \n",
    "    mnist_testset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)  \n",
    "\n",
    "    # Phase 1 : we train our model on a pre-task\n",
    "\n",
    "    #### Data\n",
    "                                    \n",
    "    # Train dataset\n",
    "    # Applying the rotation and creating new y tensors\n",
    "    train_data_loader_builder = DataLoaderBuilderFromMNIST(mnist_trainset)\n",
    "    # y\n",
    "    angles                = train_data_loader_builder.random_angle([0, 90, 180, 270])\n",
    "    train_data_loader_builder.y = angles\n",
    "    # X\n",
    "    rotated_images        = train_data_loader_builder.rotator_images(angles)\n",
    "    train_data_loader_builder.X = rotated_images\n",
    "\n",
    "    train_dataloader = train_data_loader_builder.create_dataloaders(transform=None, batch_size=32, shuffle=True, _type=torch.float32)\n",
    "    \n",
    "    #Test dataset\n",
    "    # Applying the rotation and creating new y tensors\n",
    "    test_data_loader_builder = DataLoaderBuilderFromMNIST(mnist_testset)\n",
    "    # y\n",
    "    angles                     = test_data_loader_builder.random_angle([0, 90, 180, 270])\n",
    "    test_data_loader_builder.y = angles\n",
    "    # X\n",
    "    rotated_images             = test_data_loader_builder.rotator_images(angles)\n",
    "    test_data_loader_builder.X = rotated_images\n",
    "\n",
    "    test_dataloader = test_data_loader_builder.create_dataloaders(transform=None, batch_size=32, shuffle=True, _type=torch.float32)\n",
    "    \n",
    "\n",
    "    ### Trainer\n",
    "    model     = sslModel\n",
    "    lr        = 1e-6 #1e-5 \n",
    "    optimizer = torch.optim.Adam(sslModel.parameters(), lr)\n",
    "    loss_fn   = nn.CrossEntropyLoss()\n",
    "    trainer_phase1 = Trainer(model, train_dataloader, test_dataloader, optimizer, loss_fn)\n",
    "\n",
    "    nof_epochs = 100\n",
    "    batch_size = test_dataloader.batch_size\n",
    "    file_path_save_model = \"./saving/train1_trained_model.pth\"\n",
    "    save_epoch_path = \"./saving/train1_best_accuracy.pth\"    \n",
    "    train_loss_name = \"Cross Entropy Loss\"\n",
    "    accuracy_name = \"accuracy\"\n",
    "    test_loss_name = train_loss_name\n",
    "\n",
    "    sslModel = trainer_phase1.train_model(nof_epochs, batch_size, lr, \n",
    "                                            file_path_save_model, save_epoch_path,\n",
    "                                            train_loss_name, accuracy_name, test_loss_name,\n",
    "                                            best_accuracy_is_maximal = True,\n",
    "                                            device='cuda:0')\n",
    "\n",
    "    ### Plot intermediate result\n",
    "\n",
    "\n",
    "    # Phase 2 : we train our model on a real task with few data \n",
    "\n",
    "    ### Data\n",
    "    #pourcentage_of_data\n",
    "\n",
    "    ### Trainer\n",
    "    #trainer_phase2 = Trainer()\n",
    "\n",
    "    ### Plot result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14476/1697896902.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._X = torch.tensor(self._X, dtype=torch.float32)\n",
      "/tmp/ipykernel_14476/1697896902.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self._y = torch.tensor(self._y, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "The model will be running on cuda:0 device.\n",
      "\n",
      "Epoch: 1, Cross Entropy Loss: 1.4061832427978516, accuracy: 25.06%\n",
      "Epoch: 2, Cross Entropy Loss: 1.3651574850082397, accuracy: 26.06%\n",
      "Epoch: 3, Cross Entropy Loss: 1.4202924966812134, accuracy: 27.12%\n",
      "Epoch: 4, Cross Entropy Loss: 1.3680226802825928, accuracy: 28.2%\n",
      "Epoch: 5, Cross Entropy Loss: 1.3648046255111694, accuracy: 29.16%\n",
      "Epoch: 6, Cross Entropy Loss: 1.3575501441955566, accuracy: 29.7%\n",
      "Epoch: 7, Cross Entropy Loss: 1.3402092456817627, accuracy: 29.88%\n",
      "Epoch: 8, Cross Entropy Loss: 1.3597891330718994, accuracy: 30.26%\n",
      "Epoch: 9, Cross Entropy Loss: 1.3571747541427612, accuracy: 31.18%\n",
      "Epoch: 10, Cross Entropy Loss: 1.3575960397720337, accuracy: 31.27%\n",
      "Epoch: 11, Cross Entropy Loss: 1.4070438146591187, accuracy: 31.21%\n",
      "Epoch: 12, Cross Entropy Loss: 1.4271094799041748, accuracy: 31.96%\n",
      "Epoch: 13, Cross Entropy Loss: 1.3798645734786987, accuracy: 32.15%\n",
      "Epoch: 14, Cross Entropy Loss: 1.3105170726776123, accuracy: 32.27%\n",
      "Epoch: 15, Cross Entropy Loss: 1.3081061840057373, accuracy: 32.83%\n",
      "Epoch: 16, Cross Entropy Loss: 1.3514324426651, accuracy: 33.44%\n",
      "Epoch: 17, Cross Entropy Loss: 1.3564831018447876, accuracy: 33.22%\n",
      "Epoch: 18, Cross Entropy Loss: 1.344967007637024, accuracy: 33.13%\n",
      "Epoch: 19, Cross Entropy Loss: 1.2178869247436523, accuracy: 34.14%\n",
      "Epoch: 20, Cross Entropy Loss: 1.3349859714508057, accuracy: 34.31%\n",
      "Epoch: 21, Cross Entropy Loss: 1.3527107238769531, accuracy: 34.37%\n",
      "Epoch: 22, Cross Entropy Loss: 1.289454698562622, accuracy: 34.49%\n",
      "Epoch: 23, Cross Entropy Loss: 1.2765657901763916, accuracy: 34.41%\n",
      "Epoch: 24, Cross Entropy Loss: 1.2623112201690674, accuracy: 34.59%\n",
      "Epoch: 25, Cross Entropy Loss: 1.3016431331634521, accuracy: 35.22%\n",
      "Epoch: 26, Cross Entropy Loss: 1.254008173942566, accuracy: 35.23%\n",
      "Epoch: 27, Cross Entropy Loss: 1.2334591150283813, accuracy: 35.88%\n",
      "Epoch: 28, Cross Entropy Loss: 1.1942957639694214, accuracy: 35.69%\n",
      "Epoch: 29, Cross Entropy Loss: 1.3432427644729614, accuracy: 35.89%\n",
      "Epoch: 30, Cross Entropy Loss: 1.3029388189315796, accuracy: 35.88%\n",
      "Epoch: 31, Cross Entropy Loss: 1.324535608291626, accuracy: 36.36%\n",
      "Epoch: 32, Cross Entropy Loss: 1.3637754917144775, accuracy: 36.53%\n",
      "Epoch: 33, Cross Entropy Loss: 1.2426398992538452, accuracy: 36.48%\n",
      "Epoch: 34, Cross Entropy Loss: 1.2476065158843994, accuracy: 36.45%\n",
      "Epoch: 35, Cross Entropy Loss: 1.29542875289917, accuracy: 36.66%\n",
      "Epoch: 36, Cross Entropy Loss: 1.3497055768966675, accuracy: 36.95%\n",
      "Epoch: 37, Cross Entropy Loss: 1.2391648292541504, accuracy: 37.24%\n",
      "Epoch: 38, Cross Entropy Loss: 1.2738581895828247, accuracy: 37.65%\n",
      "Epoch: 39, Cross Entropy Loss: 1.2584198713302612, accuracy: 37.6%\n",
      "Epoch: 40, Cross Entropy Loss: 1.234287977218628, accuracy: 37.7%\n",
      "Epoch: 41, Cross Entropy Loss: 1.2668267488479614, accuracy: 37.71%\n",
      "Epoch: 42, Cross Entropy Loss: 1.2524840831756592, accuracy: 37.82%\n",
      "Epoch: 43, Cross Entropy Loss: 1.2293363809585571, accuracy: 37.72%\n",
      "Epoch: 44, Cross Entropy Loss: 1.2568186521530151, accuracy: 37.99%\n",
      "Epoch: 45, Cross Entropy Loss: 1.2101125717163086, accuracy: 38.26%\n",
      "Epoch: 46, Cross Entropy Loss: 1.2665084600448608, accuracy: 37.87%\n",
      "Epoch: 47, Cross Entropy Loss: 1.2204352617263794, accuracy: 37.93%\n",
      "Epoch: 48, Cross Entropy Loss: 1.3076379299163818, accuracy: 38.02%\n",
      "Epoch: 49, Cross Entropy Loss: 1.2529670000076294, accuracy: 38.34%\n",
      "Epoch: 50, Cross Entropy Loss: 1.2318860292434692, accuracy: 38.85%\n",
      "Epoch: 51, Cross Entropy Loss: 1.2203402519226074, accuracy: 38.65%\n",
      "Epoch: 52, Cross Entropy Loss: 1.2435170412063599, accuracy: 38.77%\n",
      "Epoch: 53, Cross Entropy Loss: 1.2379714250564575, accuracy: 38.59%\n",
      "Epoch: 54, Cross Entropy Loss: 1.1854207515716553, accuracy: 38.79%\n",
      "Epoch: 55, Cross Entropy Loss: 1.290462613105774, accuracy: 39.06%\n",
      "Epoch: 56, Cross Entropy Loss: 1.2547707557678223, accuracy: 39.34%\n",
      "Epoch: 57, Cross Entropy Loss: 1.191977620124817, accuracy: 38.88%\n",
      "Epoch: 58, Cross Entropy Loss: 1.2198683023452759, accuracy: 39.48%\n",
      "Epoch: 59, Cross Entropy Loss: 1.2555131912231445, accuracy: 39.25%\n",
      "Epoch: 60, Cross Entropy Loss: 1.2375209331512451, accuracy: 39.7%\n",
      "Epoch: 61, Cross Entropy Loss: 1.1782667636871338, accuracy: 39.28%\n",
      "Epoch: 62, Cross Entropy Loss: 1.163387656211853, accuracy: 39.64%\n",
      "Epoch: 63, Cross Entropy Loss: 1.233427882194519, accuracy: 39.46%\n",
      "Epoch: 64, Cross Entropy Loss: 1.276256799697876, accuracy: 39.5%\n",
      "Epoch: 65, Cross Entropy Loss: 1.2282971143722534, accuracy: 39.57%\n",
      "Epoch: 66, Cross Entropy Loss: 1.2389678955078125, accuracy: 39.58%\n",
      "Epoch: 67, Cross Entropy Loss: 1.2442009449005127, accuracy: 39.73%\n",
      "Epoch: 68, Cross Entropy Loss: 1.1343013048171997, accuracy: 39.64%\n",
      "Epoch: 69, Cross Entropy Loss: 1.1251652240753174, accuracy: 39.66%\n",
      "Epoch: 70, Cross Entropy Loss: 1.1986207962036133, accuracy: 39.76%\n",
      "Epoch: 71, Cross Entropy Loss: 1.202735424041748, accuracy: 40.06%\n",
      "Epoch: 72, Cross Entropy Loss: 1.272485613822937, accuracy: 39.81%\n",
      "Epoch: 73, Cross Entropy Loss: 1.2613128423690796, accuracy: 40.08%\n",
      "Epoch: 74, Cross Entropy Loss: 1.2345422506332397, accuracy: 40.21%\n",
      "Epoch: 75, Cross Entropy Loss: 1.1567960977554321, accuracy: 39.77%\n",
      "Epoch: 76, Cross Entropy Loss: 1.199100136756897, accuracy: 40.13%\n",
      "Epoch: 77, Cross Entropy Loss: 1.1853185892105103, accuracy: 40.04%\n",
      "Epoch: 78, Cross Entropy Loss: 1.1639807224273682, accuracy: 40.07%\n",
      "Epoch: 79, Cross Entropy Loss: 1.2334336042404175, accuracy: 40.52%\n",
      "Epoch: 80, Cross Entropy Loss: 1.1648938655853271, accuracy: 40.1%\n",
      "Epoch: 81, Cross Entropy Loss: 1.2529716491699219, accuracy: 40.08%\n",
      "Epoch: 82, Cross Entropy Loss: 1.264728307723999, accuracy: 40.57%\n",
      "Epoch: 83, Cross Entropy Loss: 1.1724556684494019, accuracy: 40.05%\n",
      "Epoch: 84, Cross Entropy Loss: 1.1504981517791748, accuracy: 40.93%\n",
      "Epoch: 85, Cross Entropy Loss: 1.1220697164535522, accuracy: 40.51%\n",
      "Epoch: 86, Cross Entropy Loss: 1.2283903360366821, accuracy: 40.35%\n",
      "Epoch: 87, Cross Entropy Loss: 1.2004449367523193, accuracy: 40.4%\n",
      "Epoch: 88, Cross Entropy Loss: 1.200838327407837, accuracy: 40.81%\n",
      "Epoch: 89, Cross Entropy Loss: 1.1745705604553223, accuracy: 40.8%\n",
      "Epoch: 90, Cross Entropy Loss: 1.203037977218628, accuracy: 40.89%\n",
      "Epoch: 91, Cross Entropy Loss: 1.1979902982711792, accuracy: 40.48%\n",
      "Epoch: 92, Cross Entropy Loss: 1.2090580463409424, accuracy: 40.88%\n",
      "Epoch: 93, Cross Entropy Loss: 1.1940723657608032, accuracy: 40.74%\n",
      "Epoch: 94, Cross Entropy Loss: 1.1401287317276, accuracy: 40.91%\n",
      "Epoch: 95, Cross Entropy Loss: 1.180214762687683, accuracy: 41.2%\n",
      "Epoch: 96, Cross Entropy Loss: 1.0680601596832275, accuracy: 40.81%\n",
      "Epoch: 97, Cross Entropy Loss: 1.2051469087600708, accuracy: 40.99%\n",
      "Epoch: 98, Cross Entropy Loss: 1.177749514579773, accuracy: 40.93%\n",
      "Epoch: 99, Cross Entropy Loss: 1.1018617153167725, accuracy: 41.06%\n",
      "Epoch: 100, Cross Entropy Loss: 1.2036280632019043, accuracy: 41.08%\n",
      "Saving the model...\n",
      "\n",
      "Training finish.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "During training, we noted that to much angles (aka classes) to predict provokes a vanishing gradient. The extrem limit is when we try to predict 360 classes.\n",
    "When we test with four classes, with learning rate set to 1e-6, we achieve with 50 epochs an accuracy of 39%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8cc5b7cf7ab45a4eb9c5d10fcde61976ab495d4e3d71a8f87de6440d779c3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
